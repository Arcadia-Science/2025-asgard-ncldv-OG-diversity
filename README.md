# 2025-Asgard-NCLDV-OG-Diversity

# Purpose

This repository contains the scripts and analysis notebooks used to investigate the relationship between sequence diversity and structural diversity within orthologous groups (OGs) from Asgard archaea. The primary motivation was to determined whether we could find global rules to characterize the relationship of protein sequence and structure in Asgard archaea proteomes, representing ~2 billion years of evolution. We found no correlation between structural and phylogenetic diversity, and only weak correlations between sequence and structural diversity. Instead, we found that the subset of orthogroups with the least structural diversity comprise protein families where the structure is effectively resistent to sequence divergence. We

# Installation and Setup

This repository uses conda to manage software environments and installations. You can find operating system-specific instructions for installing miniconda [here](https://conda.io/projects/conda/en/latest/user-guide/install/index.html).

After installing conda and mamba, run the following commands to create the environment and set up the repository:

```bash
# Create the environment used for data processing and analysis
mamba env create -n asgard_gv_env --file envs/dev.yml
conda activate asgard_gv_env

# Install pre-commit hooks
pre-commit install
```


# Data

# Input Data:
proteome_database_v3.5.csv: The primary input database containing protein sequences, OG assignments, and pre-computed annotations (domain counts, disorder, etc.) for Asgard archaea. Generated in a prior study (DOI: xxx)

interpro_entry.txt: Reference file from InterPro for mapping IPR domain IDs to human-readable names.

downloaded_structures/: A directory containing pre-downloaded protein structures from the AlphaFold DB and RCSB PDB, organized into alphafold_structures/ and rcsb_pdb/ subdirectories. Available on zenodo

# Intermediate Data:
analysis_v3/final_master_og_properties_v2.csv: The primary integrated data table generated by the analysis notebooks, containing merged sequence, structural, and phylogenetic diversity metrics for each OG.

analysis_v3/all_vs_all_structural_metrics.csv: The raw output of the all-vs-all TM-align comparisons, containing pairwise TM-scores and RMSD values.

analysis_v3/og_sequence_diversity_v3.csv: Table of sequence-based diversity metrics (Hill Diversity, APSI, Shannon Entropy) for each OG.

analysis_v3/generated_data/df_per_column_conservation.csv: Per-column Shannon entropy values for each position in the MSA of each OG.

# Primary Output Data:
publication_figures/: Directory containing all final, publication-quality figures and statistical summary tables generated by the main analysis notebook.


# Overview

# Description of the Folder Structure

scripts/: Contains all Python scripts for the data processing pipeline (OG selection, MSA, tree building, diversity calculation, etc.).

notebooks/: Contains Jupyter notebooks (Analysis_v3.ipynb and pub_figures.ipynb) for exploratory data analysis and final figure generation.

data/: Contains raw and intermediate data files.

results/: Contains the primary data outputs from the analysis pipeline and notebooks.

publication_figures/: Contains the final, publication-ready figures.

envs/: Contains the conda environment definition file.

# Methods

This section provides example commands to run the key scripts in this repository. The commands assume they are being run from the root directory of the project.


## Main Analysis Pipeline 
1. OG selection and sequence extraction: From the existing Asgard archaea proteome database (proteome_database_v3.5.csv) we identified all Asgard orthogroups with >20 members (prepare_og_list.py) and extracted all amino acid sequences from those orthogroups into a single FASTA (fetch_og_sequences.py)

This is the core pipeline for generating the sequence and phylogenetic diversity metrics from a set of defined OGs.

1. Extract OG Sequences

This script takes a curated list of OGs and extracts all member sequences from the main proteome database into individual FASTA files.

python scripts/og_sequence_extraction.py \
    --og_list_csv analysis_outputs/analysis_esp_ogs/curated_esp_og_anchor_list_v1.csv \
    --proteome_db data/proteome_database_v3.5.csv \
    --output_dir data/data_esp_ogs/esp_raw_og_fastas

2. Generate Initial Multiple Sequence Alignments

This script runs MAFFT in parallel on the raw FASTA files generated in the previous step.

python scripts/run_initial_mafft_parallel.py \
    --input_dir data/data_esp_ogs/esp_raw_og_fastas \
    --output_dir data/data_esp_ogs/initial_mafft_alignments \
    --log_dir data/data_esp_ogs/initial_mafft_logs \
    --num_cores 8

3. Filter Alignments by Length

This script filters the initial alignments to remove fragmentary sequences, while ensuring the designated anchor sequence is always kept.

python scripts/length_filtering_keep_anchor.py \
    --input_aln_dir data/data_esp_ogs/initial_mafft_alignments \
    --output_dir data/data_esp_ogs/mafft_len_filtered_esp_output \
    --anchor_list_csv analysis_outputs/analysis_esp_ogs/curated_esp_og_anchor_list_v1.csv

4. Refine Alignments

This script implements a full refinement pipeline: it unaligns the sequences, re-aligns them with MAFFT, and then trims the new alignment with TrimAl to produce the final MSAs for tree inference.

python scripts/refine_alignments.py \
    --input-dir data/data_esp_ogs/mafft_len_filtered_esp_output \
    --output-dir data/data_esp_ogs/trimmed_fastas_for_trees_esp \
    --input-suffix "_len_filtered.aln" \
    --output-suffix "_final_trimmed.fasta" \
    --max-workers 8

5. Infer Phylogenetic Trees

This script runs FastTree in parallel on the final, trimmed and refined alignments to generate phylogenetic trees.

python scripts/run_fasttree_parallel.py \
    -i data/data_esp_ogs/trimmed_fastas_for_trees_esp \
    -o data/data_esp_ogs/fasttree_output_final_trees_esp \
    --input_suffix "_final_trimmed.fasta" \
    --output_suffix "_tree.nwk" \
    --cores 8

6. Calculate All-vs-All Structural Metrics

This script performs the core structural comparison, running TM-align on all pairs of high-quality structures within each target OG.

python scripts/calculate_all_vs_all_metrics.py \
    --og-list-csv analysis_outputs/analysis_esp_ogs/curated_esp_og_anchor_list_v1.csv \
    --proteome-db data/proteome_database_v3.5.csv \
    --pdb-dir data/downloaded_structures/alphafold_structures \
    --output-csv analysis_v3/all_vs_all_structural_metrics.csv \
    --max-workers 8

This final pipeline script reads the MSAs and trees to calculate Hill Diversity, APSI, and Shannon Entropy for each OG.

python scripts/hill_diversity_v3.py \
    --msa_dir data/data_esp_ogs/trimmed_fastas_for_trees_esp \
    --tree_dir data/data_esp_ogs/fasttree_output_final_trees_esp \
    --output_csv analysis_outputs/analysis_esp_ogs/og_diversity_metrics_esp.csv

6. Data Integration and Analysis: All computed metrics were merged into a master dataframe. OGs were categorized into "Structurally Rigid," "Structurally Plastic," and "Intermediate" profiles based on the 25th and 75th percentiles of their Mean_TMscore and StdDev_TMscore. Open-ended exploration of these data was conducted in the Analysis_V3 notebook.

7. Hypothesis Testing & Visualization: The final analysis, performed in a dedicated Jupyter Notebook (pub_figures.ipynb), tested several hypotheses:

a. The global correlation between sequence diversity (both Hill Diversity and APSI) and structural 	diversity  was assessed.

b. The distributions of domain count and intrinsic disorder were compared across structural profiles using KDE plots.

c. The relationship between sequence and structure was explored within specific functional families defined by their consensus domain architecture using faceted correlation plots.

d. Per-column Shannon entropy was analyzed to compare conservation patterns between structural profiles, leading to the "islands of conservation" hypothesis.

# Compute Specifications

Local Machine: Apple MacBook Pro M3 Max, 36 GB RAM (Used for scripting, data integration, statistical analysis, and figure generation).

AWS EC2: Used for the all-vs-all TM-align. Amazon Linux2 c6a32X large with 128 CPUs. 

Key Software: Python 3.10 (via Conda/Mamba), Pandas, NumPy, SciPy, Statsmodels, Plotly, arcadia-pycolor, BioPython, MAFFT, FastTree, TM-align.

# For Developers

This section contains information for developers who are working off of this template. Please adjust or edit this section as appropriate when you're ready to share your repo.

# GitHub templates

This template uses GitHub templates to provide checklists when making new pull requests. These templates are stored in the .github/ directory.

.gitignore
This template uses a .gitignore file to prevent certain files from being committed to the repository.

pyproject.toml
pyproject.toml is a configuration file to specify your project's metadata and to set the behavior of other tools such as linters, type checkers etc. You can learn more here

Linting
This template automates linting and formatting using GitHub Actions and the ruff linter. When you push changes to your repository, GitHub will automatically run the linter and report any errors, blocking merges until they are resolved.


